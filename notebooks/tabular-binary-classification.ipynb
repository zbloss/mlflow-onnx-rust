{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f9b2d8",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30e88f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelling Metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Modelling\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "100d95a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/tabular/binary-classification/titanic-dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e850e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = \"Survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "712a7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    left=df,\n",
    "    right=pd.get_dummies(df[\"Sex\"]),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"inner\",\n",
    ")\n",
    "df = pd.merge(\n",
    "    left=df,\n",
    "    right=pd.get_dummies(df[\"Embarked\"]),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "df[\"Cabin\"] = df[\"Cabin\"].str[0]\n",
    "df = pd.merge(\n",
    "    left=df,\n",
    "    right=pd.get_dummies(df[\"Cabin\"], prefix=\"Cabin\"),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "df = pd.merge(\n",
    "    left=df,\n",
    "    right=pd.get_dummies(df[\"Embarked\"], prefix=\"Embarked\"),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8296386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"PassengerId\", \"Name\", \"Sex\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "132625a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba64e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[target_variable]\n",
    "X = df.drop(target_variable, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=101\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a20f385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f33d766",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c37ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(true_values: list, model_predictions: list, prefix: str = None) -> dict:\n",
    "\n",
    "    classification_report_ = classification_report(\n",
    "        y_true=true_values, y_pred=model_predictions, output_dict=True\n",
    "    )\n",
    "    roc = roc_auc_score(y_true=true_values, y_score=model_predictions)\n",
    "\n",
    "    classification_report_[\"not_survived\"] = classification_report_.pop(\"0\")\n",
    "    classification_report_[\"survived\"] = classification_report_.pop(\"1\")\n",
    "\n",
    "    flattened_metrics = pd.json_normalize(classification_report_)\n",
    "    flattened_metrics[\"roc_auc_score\"] = roc\n",
    "\n",
    "    if prefix:\n",
    "        flattened_metrics.columns = [\n",
    "            f\"{prefix}_{column}\" for column in flattened_metrics.columns\n",
    "        ]\n",
    "\n",
    "    flattened_metrics = flattened_metrics.to_dict(orient=\"records\")[0]\n",
    "    return flattened_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ef3bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_tracking_uri = \"http://localhost:5000\"\n",
    "mlflow_experiment = \"binary-classification\"\n",
    "model_name = \"binary-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76cd5bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/26 19:06:48 INFO mlflow.tracking.fluent: Experiment with name 'binary-classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/zbloss/Projects/mlflow-onnx-rust/mlruns/1', creation_time=1664233609003, experiment_id='1', last_update_time=1664233609003, lifecycle_stage='active', name='binary-classification', tags={}>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_experiment(mlflow_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3263b324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zbloss/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zbloss/.local/lib/python3.10/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input)\n",
      "/usr/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'binary-classifier'.\n",
      "2022/09/26 19:06:51 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: binary-classifier, version 1\n",
      "Created version '1' of model 'binary-classifier'.\n",
      "/home/zbloss/.local/lib/python3.10/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input)\n",
      "Registered model 'binary-classifier' already exists. Creating a new version of this model...\n",
      "2022/09/26 19:06:53 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: binary-classifier, version 2\n",
      "Created version '2' of model 'binary-classifier'.\n",
      "/home/zbloss/.local/lib/python3.10/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input)\n",
      "Registered model 'binary-classifier' already exists. Creating a new version of this model...\n",
      "2022/09/26 19:06:55 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: binary-classifier, version 3\n",
      "Created version '3' of model 'binary-classifier'.\n",
      "/home/zbloss/.local/lib/python3.10/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input)\n",
      "Registered model 'binary-classifier' already exists. Creating a new version of this model...\n",
      "2022/09/26 19:06:57 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: binary-classifier, version 4\n",
      "Created version '4' of model 'binary-classifier'.\n"
     ]
    }
   ],
   "source": [
    "for model_class in [\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    XGBClassifier,\n",
    "]:\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        model = model_class()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        train_predictions = model.predict(X_train)\n",
    "        test_predictions = model.predict(X_test)\n",
    "\n",
    "        train_metrics = metrics(\n",
    "            true_values=y_train, model_predictions=train_predictions, prefix=\"train\"\n",
    "        )\n",
    "        test_metrics = metrics(\n",
    "            true_values=y_test, model_predictions=test_predictions, prefix=\"test\"\n",
    "        )\n",
    "\n",
    "        mlflow.log_metrics(metrics=train_metrics)\n",
    "        mlflow.log_metrics(metrics=test_metrics)\n",
    "\n",
    "        signature = infer_signature(X_test, test_predictions)\n",
    "        \n",
    "        if model_class == XGBClassifier:\n",
    "            mlflow.xgboost.log_model(\n",
    "                model,\n",
    "                \"model\",\n",
    "                signature=signature,\n",
    "                input_example=X_test,\n",
    "                registered_model_name=model_name,\n",
    "            )\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(\n",
    "                model,\n",
    "                \"model\",\n",
    "                signature=signature,\n",
    "                input_example=X_test,\n",
    "                registered_model_name=model_name,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "016abf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            *[\n",
    "                nn.Linear(X_train.shape[-1], X_train.shape[-1] * 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(X_train.shape[-1] * 2, X_train.shape[-1] * 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(X_train.shape[-1] * 2, X_train.shape[-1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(X_train.shape[-1], 1),\n",
    "                nn.Sigmoid(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        x = x.float()\n",
    "        y = y.unsqueeze(-1).float()\n",
    "\n",
    "        prediction = self(x)\n",
    "\n",
    "        loss = F.binary_cross_entropy(prediction, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        x, y = batch\n",
    "        x = x.float()\n",
    "        y = y.unsqueeze(-1).float()\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = F.binary_cross_entropy(prediction, y)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        x, y = batch\n",
    "        x = x.float()\n",
    "        y = y.unsqueeze(-1).float()\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = F.binary_cross_entropy(prediction, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "model = TorchModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6dc51e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, target_variable=\"Survived\"):\n",
    "        import pandas as pd\n",
    "\n",
    "        df = pd.read_csv(\"../data/tabular/binary-classification/titanic-dataset.csv\")\n",
    "        df = pd.merge(\n",
    "            left=df,\n",
    "            right=pd.get_dummies(df[\"Sex\"]),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        df = pd.merge(\n",
    "            left=df,\n",
    "            right=pd.get_dummies(df[\"Embarked\"]),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "\n",
    "        df[\"Cabin\"] = df[\"Cabin\"].str[0]\n",
    "        df = pd.merge(\n",
    "            left=df,\n",
    "            right=pd.get_dummies(df[\"Cabin\"], prefix=\"Cabin\"),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "\n",
    "        df = pd.merge(\n",
    "            left=df,\n",
    "            right=pd.get_dummies(df[\"Embarked\"], prefix=\"Embarked\"),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        columns_to_drop = [\n",
    "            \"PassengerId\",\n",
    "            \"Name\",\n",
    "            \"Sex\",\n",
    "            \"Ticket\",\n",
    "            \"Fare\",\n",
    "            \"Cabin\",\n",
    "            \"Embarked\",\n",
    "        ]\n",
    "        df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        self.y = df[target_variable].to_numpy()\n",
    "        self.X = df.drop(target_variable, axis=1).to_numpy().astype(float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03361cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TitanicDataset()\n",
    "dataloader = DataLoader(data, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c496786",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "\n",
    "test_size *= len(data)\n",
    "val_size *= len(data)\n",
    "test_size = int(test_size)\n",
    "val_size = int(val_size)\n",
    "\n",
    "train_size = len(data) - test_size - val_size\n",
    "\n",
    "train, test, val = random_split(data, (train_size, test_size, val_size))\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c269eb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=pl.loggers.MLFlowLogger(\n",
    "        experiment_name=mlflow_experiment,\n",
    "        tracking_uri=mlflow_tracking_uri,\n",
    "    ),\n",
    "    max_epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "960e9a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 3.3 K \n",
      "-------------------------------------\n",
      "3.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016197681427001953,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zbloss/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:489: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/zbloss/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/zbloss/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014175176620483398,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897f598730524333b54b02813c389ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013255119323730469,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018175363540649414,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015276908874511719,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015157699584960938,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012087821960449219,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620efb6ffb0240589ab496908086b5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013249635696411133,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015413761138916016,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015596151351928711,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012039899826049805,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011689186096191406,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c29312e096941288bef4e8391084c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013674259185791016,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011945724487304688,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012092828750610352,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012735366821289062,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011925935745239258,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e933e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zbloss/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01714038848876953,
       "initial": 0,
       "n": 0,
       "ncols": 190,
       "nrows": 46,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5091df63638e4cdbb2116cbd57329b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3daf6ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'binary-classifier' already exists. Creating a new version of this model...\n",
      "2022/09/26 19:07:13 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: binary-classifier, version 5\n",
      "Created version '5' of model 'binary-classifier'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    preds = [model(torch.tensor(x).float()) for x, y in train]\n",
    "    train_predictions = (\n",
    "        (torch.stack(preds).reshape(-1) > 0.5).detach().numpy().astype(int)\n",
    "    )\n",
    "\n",
    "    preds = [model(torch.tensor(x).float()) for x, y in test]\n",
    "    test_predictions = (\n",
    "        (torch.stack(preds).reshape(-1) > 0.5).detach().numpy().astype(int)\n",
    "    )\n",
    "\n",
    "    train_metrics = metrics(\n",
    "        true_values=[y for x, y in train],\n",
    "        model_predictions=train_predictions,\n",
    "        prefix=\"train\",\n",
    "    )\n",
    "    test_metrics = metrics(\n",
    "        true_values=[y for x, y in test],\n",
    "        model_predictions=test_predictions,\n",
    "        prefix=\"test\",\n",
    "    )\n",
    "\n",
    "    mlflow.log_metrics(metrics=train_metrics)\n",
    "    mlflow.log_metrics(metrics=test_metrics)\n",
    "\n",
    "    x = train[0][0]\n",
    "    signature = infer_signature(x, model(torch.tensor(x).float()).detach().numpy())\n",
    "    mlflow.pytorch.log_model(\n",
    "        model,\n",
    "        \"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_test,\n",
    "        registered_model_name=model_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07fe10b",
   "metadata": {},
   "source": [
    "## Load and Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb4f416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper as h\n",
    "from onnx import TensorProto as tp\n",
    "from onnx import checker\n",
    "from onnx import save\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "import onnxruntime\n",
    "from skl2onnx import __max_supported_opset__\n",
    "\n",
    "import json\n",
    "import onnxmltools\n",
    "from onnxconverter_common.data_types import FloatTensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3f1464cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = X_train.to_numpy()[0].reshape(1, -1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6adaaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_path: model\n",
      "flavors:\n",
      "  python_function:\n",
      "    data: model.xgb\n",
      "    env: conda.yaml\n",
      "    loader_module: mlflow.xgboost\n",
      "    python_version: 3.10.7\n",
      "  xgboost:\n",
      "    code: null\n",
      "    data: model.xgb\n",
      "    model_class: xgboost.sklearn.XGBClassifier\n",
      "    xgb_version: 1.6.2\n",
      "mlflow_version: 1.29.0\n",
      "model_uuid: 37cecb1012894c9c92ea89537ce1ca73\n",
      "run_id: c5af0f3cd17d4f9b9639e6b2e72dc20c\n",
      "saved_input_example_info:\n",
      "  artifact_path: input_example.json\n",
      "  pandas_orient: split\n",
      "  type: dataframe\n",
      "signature:\n",
      "  inputs: '[{\"name\": \"Pclass\", \"type\": \"long\"}, {\"name\": \"Age\", \"type\": \"double\"},\n",
      "    {\"name\": \"SibSp\", \"type\": \"long\"}, {\"name\": \"Parch\", \"type\": \"long\"}, {\"name\":\n",
      "    \"female\", \"type\": \"integer\"}, {\"name\": \"male\", \"type\": \"integer\"}, {\"name\": \"C\",\n",
      "    \"type\": \"integer\"}, {\"name\": \"Q\", \"type\": \"integer\"}, {\"name\": \"S\", \"type\": \"integer\"},\n",
      "    {\"name\": \"Cabin_A\", \"type\": \"integer\"}, {\"name\": \"Cabin_B\", \"type\": \"integer\"},\n",
      "    {\"name\": \"Cabin_C\", \"type\": \"integer\"}, {\"name\": \"Cabin_D\", \"type\": \"integer\"},\n",
      "    {\"name\": \"Cabin_E\", \"type\": \"integer\"}, {\"name\": \"Cabin_F\", \"type\": \"integer\"},\n",
      "    {\"name\": \"Cabin_G\", \"type\": \"integer\"}, {\"name\": \"Cabin_T\", \"type\": \"integer\"},\n",
      "    {\"name\": \"Embarked_C\", \"type\": \"integer\"}, {\"name\": \"Embarked_Q\", \"type\": \"integer\"},\n",
      "    {\"name\": \"Embarked_S\", \"type\": \"integer\"}]'\n",
      "  outputs: '[{\"type\": \"tensor\", \"tensor-spec\": {\"dtype\": \"int64\", \"shape\": [-1]}}]'\n",
      "utc_time_created: '2022-09-26 23:06:56.039980'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 4\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "mlflow_model = mlflow.pyfunc.load_model(model_uri=model_uri)\n",
    "print(mlflow_model.metadata.to_yaml())\n",
    "ml_flavor = mlflow_model.metadata.to_dict()[\"flavors\"][\"python_function\"][\n",
    "    \"loader_module\"\n",
    "]\n",
    "\n",
    "if ml_flavor == \"mlflow.sklearn\":\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    prediction = model.predict(sample_input)\n",
    "\n",
    "if ml_flavor == \"mlflow.pytorch\":\n",
    "    model = mlflow.pytorch.load_model(model_uri)\n",
    "    prediction = model(torch.tensor(sample_input).float())\n",
    "    \n",
    "if ml_flavor == \"mlflow.xgboost\":\n",
    "    model = mlflow.xgboost.load_model(model_uri)\n",
    "    prediction = model.predict(sample_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a54d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c1f05ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9b3b0342",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = np.array(mlflow.artifacts.load_dict(f'{model_uri}/input_example.json')['data']).shape[-1]\n",
    "initial_type = [(\"float_input\", FloatTensorType([None, number_of_features]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f2b31f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.09830367565155029,\n",
       "  0.9001232981681824,\n",
       "  0.012955546379089355,\n",
       "  0.8799967765808105,\n",
       "  0.05108916759490967,\n",
       "  0.6351413726806641,\n",
       "  0.28915196657180786,\n",
       "  0.8558712601661682,\n",
       "  0.3940802216529846,\n",
       "  0.6569401621818542,\n",
       "  0.09095829725265503,\n",
       "  0.11667466163635254,\n",
       "  0.7198678255081177,\n",
       "  0.6807432770729065,\n",
       "  0.5608528256416321,\n",
       "  0.7539402842521667,\n",
       "  0.7674431204795837,\n",
       "  0.9450421333312988,\n",
       "  0.17658114433288574,\n",
       "  0.5480032563209534]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((1, number_of_features)).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdcfa2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5125cbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxmltools.convert.convert_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3520584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ml_flavor == \"mlflow.sklearn\":\n",
    "    initial_type = [(\"float_input\", FloatTensorType([None, sample_input.shape[-1]]))]\n",
    "    onx = convert_sklearn(model, initial_types=initial_type)\n",
    "    with open(\"model.onnx\", \"wb\") as f:\n",
    "        f.write(onx.SerializeToString())\n",
    "        f.close()\n",
    "\n",
    "if ml_flavor == \"mlflow.pytorch\":\n",
    "    # Export the model\n",
    "    torch.onnx.export(\n",
    "        model,  # model being run\n",
    "        torch.tensor(\n",
    "            sample_input\n",
    "        ).float(),  # model input (or a tuple for multiple inputs)\n",
    "        \"model.onnx\",  # where to save the model (can be a file or file-like object)\n",
    "        export_params=True,  # store the trained parameter weights inside the model file\n",
    "        do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "        input_names=[\"float_input\"],  # the model's input names\n",
    "        output_names=[\"output_label\"],  # the model's output names\n",
    "        dynamic_axes={\n",
    "            \"float_input\": {0: \"batch_size\"},  # variable length axes\n",
    "            \"output_label\": {0: \"batch_size\"},\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "11e0b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c209810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('float_input', 'output_label')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(\"model.onnx\")\n",
    "input_name = session.get_inputs()[0].name\n",
    "label_name = session.get_outputs()[0].name\n",
    "\n",
    "input_name, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6154ef1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25795278]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onx = session.run([label_name], {input_name: sample_input})[0]\n",
    "pred_onx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6cde7a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 28.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e561b27",
   "metadata": {},
   "source": [
    "## Debug Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c17c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "base_url = \"http://localhost:8000\"\n",
    "endpoint = \"predict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86312d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"data\": sample_input.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "271cfbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [[1.0,\n",
       "   28.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0]]}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eb3723d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    url=f\"{base_url}/{endpoint}\",\n",
    "    headers={\"Content-Type\": \"application/json\", \"accept\": \"application/json\"},\n",
    "    data=json.dumps(payload),\n",
    ")\n",
    "response.status_code\n",
    "prediction = response.json()[\"prediction\"]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6bfb8e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    url=f\"{base_url}/predict-without-onnx\",\n",
    "    headers={\"Content-Type\": \"application/json\", \"accept\": \"application/json\"},\n",
    "    data=json.dumps(payload),\n",
    ")\n",
    "response.status_code\n",
    "prediction = response.json()[\"prediction\"]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99e54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
